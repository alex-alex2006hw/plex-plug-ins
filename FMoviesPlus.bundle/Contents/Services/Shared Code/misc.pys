#!/usr/bin/env python
# -*- coding: utf-8 -*-

#########################################################################################################
#
# Misc scrapper
#
# Coder Alpha
# https://github.com/coder-alpha
#
#
#########################################################################################################

import re, json
import sys,urllib2,HTMLParser,urllib,urlparse
import random, time, cookielib
import base64

from __builtin__ import eval


#-------------------------------------------------------------------------------------------------------------
# Enforce IPv4 for GetlinkAPI nks Google li
# do this once at program startup
# Reference: http://stackoverflow.com/questions/2014534/force-python-mechanize-urllib2-to-only-use-a-requests
#--------------------
import socket
origGetAddrInfo = socket.getaddrinfo

def getAddrInfoWrapper(host, port, family=0, socktype=0, proto=0, flags=0):
	return origGetAddrInfo(host, port, socket.AF_INET, socktype, proto, flags)

# #replace the original socket.getaddrinfo by our version
# socket.getaddrinfo = getAddrInfoWrapper
# socket.has_ipv6 = False
#-------------------------------------------------------------------------------------------------------------

GLOBAL_TIMEOUT_FOR_HTTP_REQUEST = 15
HTTP_GOOD_RESP_CODES = ['200','206']
	
USER_AGENT = "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0"
IE_USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; AS; rv:11.0) like Gecko'
FF_USER_AGENT = 'Mozilla/5.0 (Windows NT 6.3; rv:36.0) Gecko/20100101 Firefox/36.0'
OPERA_USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36 OPR/34.0.2036.50'
IOS_USER_AGENT = 'Mozilla/5.0 (iPhone; CPU iPhone OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5376e Safari/8536.25'
ANDROID_USER_AGENT = 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'
#SMU_USER_AGENT = 'URLResolver for Kodi/%s' % (addon_version)

IP_OVERIDE = True

RE_SUB1 = Regex(r'(?m)(^[^\#])')
RE_SOURCES = Regex(r'(?m)(^.+?\d+/(\d+).+$)')

supported_hosts = ['mycloud.to','mcloud.to','rapidvideo.com']

def resolve(url, https_skip, test=False, strip_url=True):
	video_urlf = None
	
	if 'https:' not in url and 'http:' not in url:
		url = 'http:' + url
	ourl = url
	#Log(ourl)
	data = {'test':'test'}
	
	try:
		myParams = {}
		
		#Log(page_data_string)
		video_url_a = []
		
		if 'rapidvideo.' in ourl:
			myheaders = {}
			myheaders['User-Agent'] = 'Mozilla'
			myheaders['Referer'] = ourl
			myParams['headers'] = myheaders
			
			if '&q=' in ourl:
				ourl_s = ourl.split('&q=')
				ourl = ourl_s[0]
				quals = [ourl_s[1]]
			else:
				quals = ['1080p','720p','480p','360p']
			
			for qs in quals:
				try:
					page_data_string = request((ourl + '&q=%s') % qs, headers=myheaders, httpsskip=True)
					page_data_elems = HTML.ElementFromString(page_data_string)
					try:
						video_url = page_data_elems.xpath(".//div[@id='home_video']//source/@src")[0]
					except:
						video_url = None
					try:
						res = page_data_elems.xpath(".//div[@id='home_video']//source/@data-res")[0]
					except:
						res = qs
						
					if video_url != None and res != None:
						f_i = {'file':video_url, 'label':res}
						video_url_a.append(f_i)
				except:
					pass
			
			video_urlf = video_url_a
			
		elif 'mycloud.' in ourl or 'mcloud.' in ourl:
			#Log('============ MyCloud URL ==================')
			myheaders = {}
			myheaders['User-Agent'] = 'Mozilla'
			myheaders['Referer'] = 'http://mcloud.to'
			myParams['headers'] = myheaders
			
			if strip_url == True and 'mycloud.' in url or 'mcloud.' in url:
				try:
					if '?' in ourl:
						data = urlparse.parse_qs(ourl.split('?')[1])
						kurl = ourl.split('?')[0]
					else:
						kurl = ourl
						data = {'a.url':'https%3A%2F%2Ffmovies.to%2Facode%2Fplayer.html','a.close':0,'ui':['ZwrN0oNRXfRP686L3Z3BPkXInMs']}
				except:
					data.update({'a.url':'https%3A%2F%2Ffmovies.to%2Facode%2Fplayer.html','a.close':0,'ui':['ZwrN0oNRXfRP686L3Z3BPkXInMs']})
					kurl = ourl
					
				#Log(data)
				url = kurl + '?ui=%s' % data['ui'][0].replace('=','')
				if 'https:' not in url and 'http:' not in url:
					url = 'http:' + url
			
			page_data_string = request(url, headers=myheaders, httpsskip=True)
			
			if 'Sorry, the page you are looking for could not be found.' not in page_data_string and 'This video is in processing' not in page_data_string:	
				json_data_str = re.findall(r'({\".*(.*m3u8|.mp4|.flv).*\"})', page_data_string)[0][0]
				json_data = json.loads(json_data_str)
				video_url = json_data['file']
				if 'https:' not in video_url and 'http:' not in video_url:
					video_url = 'http:' + video_url
				
				#Log('=======video_urls_data========')
				video_urls_data = request(video_url, headers=myheaders, httpsskip=True)
				
				if video_urls_data == None or video_urls_data == '':
					raise ValueError('M3U8 URL is empty')
				#Log('video_urls_data ------------> %s' % video_urls_data)
				
				try:
					video_urls_arr = re.findall(r'(hls.*)', video_urls_data)
					#Log('video_urls_arr ------------> %s' % video_urls_arr)
					if len(video_urls_arr) == 0:
						raise
					#Log('=======video_urls_data========')
					for v in video_urls_arr:
						str_url = video_url.split('list.m3u8')[0] + v
						#str_url = video_url
						f_i = {'file':str_url, 'label':v.split('/')[1]}
						video_url_a.append(f_i)
				except:
					f_i = {'file':video_url, 'label':'720'}
					video_url_a.append(f_i)
				video_urlf = video_url_a
				Log('video_urlf ------------> %s' % video_urlf)
				
				if test == True:
					Log('*** Testing MyCloud ***')
					vurls = mycloud_streams(video_urlf[len(video_urlf)-1], https_skip, myheaders)
			
	except Exception as e:
		Log('Misc.pys > resolve > Error : %s' % e)
		pass
		
	return video_urlf, base64.b64encode(json.dumps(myParams)), True
	
#
# Ref: https://github.com/Twoure/9anime.bundle/blob/6ce7aff245ef6769f2a0a6457281d8891b8452fa/Contents/Services/URL/9anime/ServiceCode.pys#L204...L222
# Author: Twoure
#
####################################################################################################
def mycloud_streams(hls_url, https_skip, headers=None):

	vurls = list()
	hls_url = hls_url['file']
	Log.Debug('Requesting %s' % hls_url)
	
	if https_skip:
		page = request(hls_url, headers=headers, httpsskip=True)
	else:
		page = HTTP.Request(hls_url, headers=headers).content
		
	Log("MyCloud m3u8 contents")
	Log("Headers: %s" % headers)
	Log(page)
	#page = RE_SUB1.sub(hls_url.rsplit('/', 1)[0]+r'/\1', page)
	#for (u, r) in RE_SOURCES.findall(page):
	#	vurls.append({'file': u, 'label': int(r)})
		
	#return vurls
	
####################################################################################################
def error(url, https_skip):
	error = ''
	ourl = url
	
	try:
		headers = {}
		headers['User-Agent'] = 'Mozilla5'
		headers['Referer'] = 'http://mycloud.to'
		data = {}
		
		if 'mycloud.' in url or 'mcloud.' in url:
			try:
				if '?' in ourl:
					data = urlparse.parse_qs(ourl.split('?')[1])
					kurl = ourl.split('?')[0]
				else:
					kurl = ourl
					data = {'a.url':'https%3A%2F%2Ffmovies.to%2Facode%2Fplayer.html','a.close':0,'ui':['ZwrN0oNRXfRP686L3Z3BPkXInMs']}
			except:
				data.update({'a.url':'https%3A%2F%2Ffmovies.to%2Facode%2Fplayer.html','a.close':0,'ui':['ZwrN0oNRXfRP686L3Z3BPkXInMs']})
				kurl = ourl
				
			#Log(data)
			url = kurl + '?ui=%s' % data['ui'][0].replace('=','')
			if 'https:' not in url and 'http:' not in url:
				url = 'http:' + url
		
		#Log('misc>error : %s' % url)
		page_data_string = request(url, httpsskip=True)
		#Log(page_data_string)
		
		if page_data_string != None:
			if ('mycloud.' in ourl or 'mcloud.' in ourl) and 'Sorry, the page you are looking for could not be found.' in page_data_string:
				error = 'URL Error.'
			elif ('mycloud.' in ourl or 'mcloud.' in ourl) and 'This video is in processing' in page_data_string:
				error = 'Video is in processing, try again later.'
		else:
			error = 'Page returned None'
	except:
		error = 'Page could not be retrieved'
		
	return error



def request(url, close=True, redirect=True, followredirect=False, error=False, proxy=None, post=None, headers=None, mobile=False, limit=None, referer=None, cookie=None, output='', timeout='30', httpsskip=False, use_web_proxy=False, XHR=False, IPv4=False):

# output extended = 4, response = 2, responsecodeext = 2
	
	try:
		handlers = []
		redirectURL = url
		
		if IPv4 == True:
			setIP4()
		
		if error==False and not proxy == None:
			handlers += [urllib2.ProxyHandler({'http':'%s' % (proxy)}), urllib2.HTTPHandler]
			opener = urllib2.build_opener(*handlers)
			opener = urllib2.install_opener(opener)

		if error==False and output == 'cookie2' or output == 'cookie' or output == 'extended' or not close == True:
			cookies = cookielib.LWPCookieJar()
			if httpsskip or use_web_proxy:
				handlers += [urllib2.HTTPHandler(), urllib2.HTTPCookieProcessor(cookies)]
			else:
				handlers += [urllib2.HTTPHandler(), urllib2.HTTPSHandler(), urllib2.HTTPCookieProcessor(cookies)]
			opener = urllib2.build_opener(*handlers)
			opener = urllib2.install_opener(opener)
			
		try:
			if error==False:
				if sys.version_info < (2, 7, 9): raise Exception()
				import ssl; ssl_context = ssl.create_default_context()
				ssl_context.check_hostname = False
				ssl_context.verify_mode = ssl.CERT_NONE
				handlers += [urllib2.HTTPSHandler(context=ssl_context)]
				opener = urllib2.build_opener(*handlers)
				opener = urllib2.install_opener(opener)
		except:
			pass

		try: headers.update(headers)
		except: headers = {}
		if 'User-Agent' in headers:
			pass
		elif not mobile == True:
			#headers['User-Agent'] = agent()
			#headers['User-Agent'] = Constants.USER_AGENT
			headers['User-Agent'] = randomagent()		
		else:
			headers['User-Agent'] = 'Apple-iPhone/701.341'
		if 'Referer' in headers:
			pass
		elif referer == None:
			try:
				headers['Referer'] = '%s://%s/' % (urlparse.urlparse(url).scheme, urlparse.urlparse(url).netloc)
			except:
				pass
		else:
			headers['Referer'] = referer
		if not 'Accept-Language' in headers:
			headers['Accept-Language'] = 'en-US'
		if 'X-Requested-With' in headers:
			pass
		elif XHR == True:
			headers['X-Requested-With'] = 'XMLHttpRequest'
		if 'Cookie' in headers:
			pass
		elif not cookie == None:
			headers['Cookie'] = cookie

		if error==False and redirect == False:
			class NoRedirection(urllib2.HTTPErrorProcessor):
				def http_response(self, request, response): 
					if IPv4 == True:
						setIP6()
					return response

			opener = urllib2.build_opener(NoRedirection)
			opener = urllib2.install_opener(opener)

			try: del headers['Referer']
			except: pass
			
		redirectHandler = None
		urlList = []
		if error==False and followredirect:
			class HTTPRedirectHandler(urllib2.HTTPRedirectHandler):
				def redirect_request(self, req, fp, code, msg, headers, newurl):
					newreq = urllib2.HTTPRedirectHandler.redirect_request(self,
						req, fp, code, msg, headers, newurl)
					if newreq is not None:
						self.redirections.append(newreq.get_full_url())
					if IPv4 == True:
						setIP6()
					return newreq
			
			redirectHandler = HTTPRedirectHandler()
			redirectHandler.max_redirections = 10
			redirectHandler.redirections = [url]

			opener = urllib2.build_opener(redirectHandler)
			opener = urllib2.install_opener(opener)

		request = urllib2.Request(url, data=post, headers=headers)
		#print request

		try:
			response = urllib2.urlopen(request, timeout=int(timeout))
			if followredirect:
				for redURL in redirectHandler.redirections:
					urlList.append(redURL) # make a list, might be useful
					redirectURL = redURL
					
		except urllib2.HTTPError as response:
			
			try:
				resp_code = response.code
			except:
				resp_code = None
			
			try:
				content = response.read()
			except:
				content = ''
				
			if response.code == 503:
				#Log("AAAA- CODE %s|%s " % (url, response.code))
				if 'cf-browser-verification' in content:
					print("CF-OK")

					netloc = '%s://%s' % (urlparse.urlparse(url).scheme, urlparse.urlparse(url).netloc)
					#cf = cache.get(cfcookie, 168, netloc, headers['User-Agent'], timeout)
					cfc = cfcookie()
					cf = cfc.get(netloc, headers['User-Agent'], timeout)
					
					headers['Cookie'] = cf
					request = urllib2.Request(url, data=post, headers=headers)
					response = urllib2.urlopen(request, timeout=int(timeout))
				elif error == False:
					if IPv4 == True:
						setIP6()
					return
				elif error == True:
					return '%s: %s' % (response.code, response.reason), content
			elif response.code == 307:
				#Log("AAAA- Response read: %s" % response.read(5242880))
				#Log("AAAA- Location: %s" % (response.headers['Location'].rstrip()))
				cookie = ''
				try: cookie = '; '.join(['%s=%s' % (i.name, i.value) for i in cookies])
				except: pass
				headers['Cookie'] = cookie
				request = urllib2.Request(response.headers['Location'], data=post, headers=headers)
				response = urllib2.urlopen(request, timeout=int(timeout))
				#Log("AAAA- BBBBBBB %s" %  response.code)
			elif resp_code != None:
				if IPv4 == True:
					setIP6()
				if output == 'response':
					return (resp_code, None)
				return resp_code
			elif error == False:
				#print ("Response code",response.code, response.msg,url)
				if IPv4 == True:
					setIP6()
				return
			else:
				if IPv4 == True:
					setIP6()
				return
		except Exception as e:
			Log ('Error misc.py>request : %s' % url)
			Log ('Error misc.py>request : %s' % (e.args))
			if IPv4 == True:
				setIP6()
			if output == 'response':
				return (None, None)
			return None

		if output == 'cookie':
			try: result = '; '.join(['%s=%s' % (i.name, i.value) for i in cookies])
			except: pass
			try: result = cf
			except: pass

		elif output == 'response':
			if limit == '0':
				result = (str(response.code), response.read(224 * 1024))
			elif not limit == None:
				result = (str(response.code), response.read(int(limit) * 1024))
			else:
				result = (str(response.code), response.read(5242880))
				
		elif output == 'responsecodeext':
			result = (str(response.code),redirectURL)
			
		elif output == 'responsecode':
			result = str(response.code)

		elif output == 'chunk':
			try: content = int(response.headers['Content-Length'])
			except: content = (2049 * 1024)
			#Log('CHUNK %s|%s' % (url,content))
			if content < (2048 * 1024):
				if IPv4 == True:
					setIP6()
				return
			result = response.read(16 * 1024)
			if close == True: response.close()
			if IPv4 == True:
				setIP6()
			return result

		elif output == 'extended':
			try: cookie = '; '.join(['%s=%s' % (i.name, i.value) for i in cookies])
			except: pass
			try: cookie = cf
			except: pass
			content = response.headers
			result = response.read(5242880)
			if IPv4 == True:
				setIP6()
			return (result, headers, content, cookie)

		elif output == 'geturl':
			result = response.geturl()

		elif output == 'headers':
			content = response.headers
			if IPv4 == True:
				setIP6()
			return content

		else:
			if limit == '0':
				result = response.read(224 * 1024)
			elif not limit == None:
				result = response.read(int(limit) * 1024)
			else:
				result = response.read(5242880)

		if close == True:
			response.close()

		if IPv4 == True:
			setIP6()
		return result
		
	except Exception as e:
		Log ('ERROR misc.py>request %s, %s' % (e.args,url))
		if IPv4 == True:
			setIP6()
		return
		
def agent():
	return randomagent()

def randomagent():
	BR_VERS = [
		['%s.0' % i for i in xrange(18, 43)],
		['37.0.2062.103', '37.0.2062.120', '37.0.2062.124', '38.0.2125.101', '38.0.2125.104', '38.0.2125.111', '39.0.2171.71', '39.0.2171.95', '39.0.2171.99', '40.0.2214.93', '40.0.2214.111',
		 '40.0.2214.115', '42.0.2311.90', '42.0.2311.135', '42.0.2311.152', '43.0.2357.81', '43.0.2357.124', '44.0.2403.155', '44.0.2403.157', '45.0.2454.101', '45.0.2454.85', '46.0.2490.71',
		 '46.0.2490.80', '46.0.2490.86', '47.0.2526.73', '47.0.2526.80'],
		['11.0']]
	WIN_VERS = ['Windows NT 10.0', 'Windows NT 7.0', 'Windows NT 6.3', 'Windows NT 6.2', 'Windows NT 6.1', 'Windows NT 6.0', 'Windows NT 5.1', 'Windows NT 5.0']
	FEATURES = ['; WOW64', '; Win64; IA64', '; Win64; x64', '']
	RAND_UAS = ['Mozilla/5.0 ({win_ver}{feature}; rv:{br_ver}) Gecko/20100101 Firefox/{br_ver}',
				'Mozilla/5.0 ({win_ver}{feature}) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{br_ver} Safari/537.36']
	index = random.randrange(len(RAND_UAS))
	return RAND_UAS[index].format(win_ver=random.choice(WIN_VERS), feature=random.choice(FEATURES), br_ver=random.choice(BR_VERS[index]))
		
def setIP4(setoveride=False):

	if setoveride==False and IP_OVERIDE == True:
		return
	#replace the original socket.getaddrinfo by our version
	socket.getaddrinfo = getAddrInfoWrapper
	socket.has_ipv6 = False
	
def setIP6(setoveride=False):

	if setoveride==False and IP_OVERIDE == True:
		return
	#replace the IP4 socket.getaddrinfo by original
	socket.getaddrinfo = origGetAddrInfo
	socket.has_ipv6 = True
